{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XnmuanR6NWWK",
        "outputId": "388c60ec-0c73-49d4-b209-febd95395f8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.1.4)\n",
            "Collecting openai\n",
            "  Downloading openai-1.42.0-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting jiter<1,>=0.4.0 (from openai)\n",
            "  Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.7.4)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Downloading openai-1.42.0-py3-none-any.whl (362 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m362.9/362.9 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jiter, h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 jiter-0.5.0 openai-1.42.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iMdh43OoNmjQ",
        "outputId": "13b4502a-6186-4e2c-8ffb-8bc8627dcccb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4rYggpC1NoEG"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "\n",
        "import os\n",
        "from google.colab import userdata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-thekuOrNpi-",
        "outputId": "04425995-60a7-4880-ef38-7cc0e5c1cbfd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OpenAI API key set successfully.\n"
          ]
        }
      ],
      "source": [
        "# Verify and set the API key\n",
        "openai_api_key = userdata.get('OPENAI_API_KEY')\n",
        "if openai_api_key is None or openai_api_key.strip() == \"\":\n",
        "    raise ValueError(\"OpenAI API key is not set. Please set it in Colab secrets.\")\n",
        "\n",
        "openai.api_key = openai_api_key\n",
        "print(\"OpenAI API key set successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JqiakvRyNrXU"
      },
      "outputs": [],
      "source": [
        "# Load existing data\n",
        "keyword_driven_df = pd.read_csv('/content/drive/MyDrive/WORKS/SOFTWARE-DRIVEN-TEST AUTOMATION/dataset & info/SDT UAR Test Cases/keyDriven_testcases.csv')\n",
        "data_driven_df = pd.read_csv('/content/drive/MyDrive/WORKS/SOFTWARE-DRIVEN-TEST AUTOMATION/dataset & info/SDT UAR Test Cases/Data_driven_testcases.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6omMGdNyOH41"
      },
      "outputs": [],
      "source": [
        "def get_examples(df, n=3):\n",
        "    return df.sample(n).to_dict('records')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8LIR3ybFOb_K"
      },
      "outputs": [],
      "source": [
        "def create_prompt(examples, test_type):\n",
        "    prompt = f\"Generate a new {test_type} test case following EXACTLY the structure, style, and column names of these examples:\\n\\n\"\n",
        "    for i, example in enumerate(examples, 1):\n",
        "        prompt += f\"Example {i}:\\n\"\n",
        "        for key, value in example.items():\n",
        "            prompt += f\"{key}: {value}\\n\"\n",
        "        prompt += \"\\n\"\n",
        "    prompt += f\"Now, create a new {test_type} test case following this EXACT structure and style. Ensure all fields are filled correctly and the content is relevant to {test_type} testing. Make sure to maintain consistency with the existing data in terms of keywords, prompt types, and documentation style.\"\n",
        "    return prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BCI4W3Y4OfIx"
      },
      "outputs": [],
      "source": [
        "def generate_test_case(prompt):\n",
        "    try:\n",
        "        response = openai.chat.completions.create(\n",
        "            model=\"gpt-4\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are a test case generator that precisely follows given examples and instructions. Ensure consistency with existing data and maintain the same column structure.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "            max_tokens=1000\n",
        "        )\n",
        "        return response.choices[0].message.content\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating test case: {e}\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4SHN-7qTOiT4"
      },
      "outputs": [],
      "source": [
        "def parse_generated_case(content, df):\n",
        "    lines = content.split('\\n')\n",
        "    parsed_case = {col: '' for col in df.columns}\n",
        "    current_key = None\n",
        "    for line in lines:\n",
        "        if ': ' in line:\n",
        "            key, value = line.split(': ', 1)\n",
        "            current_key = key.strip()\n",
        "            if current_key in parsed_case:\n",
        "                parsed_case[current_key] = value.strip()\n",
        "        elif current_key and current_key in parsed_case:\n",
        "            parsed_case[current_key] += '\\n' + line.strip()\n",
        "    return parsed_case"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rnwNgbGHOkPv"
      },
      "outputs": [],
      "source": [
        "def generate_new_test_cases(df, test_type, count):\n",
        "    new_test_cases = []\n",
        "    for _ in tqdm(range(count)):\n",
        "        examples = get_examples(df)\n",
        "        prompt = create_prompt(examples, test_type)\n",
        "        generated_content = generate_test_case(prompt)\n",
        "        if generated_content:\n",
        "            parsed_case = parse_generated_case(generated_content, df)\n",
        "            new_test_cases.append(parsed_case)\n",
        "        time.sleep(1)  # To avoid rate limiting\n",
        "    return new_test_cases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHstEhl1Ol7_",
        "outputId": "1cf4a1f9-a48b-44ca-9f5c-28c8c0392b95"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 350/350 [1:59:04<00:00, 20.41s/it]\n",
            " 75%|███████▍  | 261/350 [1:30:42<29:51, 20.13s/it]"
          ]
        }
      ],
      "source": [
        "# Generate new test cases\n",
        "new_keyword_cases = generate_new_test_cases(keyword_driven_df, 'keyword-driven', 350)\n",
        "new_data_cases = generate_new_test_cases(data_driven_df, 'data-driven', 350)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ttIE4lh0Oq_Z"
      },
      "outputs": [],
      "source": [
        "# Convert to DataFrames\n",
        "new_keyword_df = pd.DataFrame(new_keyword_cases)\n",
        "new_data_df = pd.DataFrame(new_data_cases)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rbVZgwE1Ot_j"
      },
      "outputs": [],
      "source": [
        "# # Save the combined datasets\n",
        "new_keyword_df.to_excel('/content/drive/MyDrive/WORKS/SOFTWARE-DRIVEN-TEST AUTOMATION/dataset & info/SDT UAR Test Cases/test_keyword_generated.xlsx', index=False)\n",
        "new_data_df.to_excel('/content/drive/MyDrive/WORKS/SOFTWARE-DRIVEN-TEST AUTOMATION/dataset & info/SDT UAR Test Cases/test_data_generated.xlsx', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cp96Ybu0O9yW"
      },
      "outputs": [],
      "source": [
        "# # Save the combined datasets\n",
        "new_keyword_df.to_csv('/content/drive/MyDrive/WORKS/SOFTWARE-DRIVEN-TEST AUTOMATION/dataset & info/SDT UAR Test Cases/test_keyword_generated.csv', index=False)\n",
        "new_data_df.to_csv('/content/drive/MyDrive/WORKS/SOFTWARE-DRIVEN-TEST AUTOMATION/dataset & info/SDT UAR Test Cases/test_data_generated.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QbIKI72ePwSn"
      },
      "outputs": [],
      "source": [
        "# # Combine with existing data\n",
        "combined_keyword_df = pd.concat([keyword_driven_df, new_keyword_df], ignore_index=True)\n",
        "combined_data_df = pd.concat([data_driven_df, new_data_df], ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L223GN1LgKow"
      },
      "outputs": [],
      "source": [
        "# # Save the combined datasets\n",
        "combined_keyword_df.to_csv('/content/drive/MyDrive/WORKS/SOFTWARE-DRIVEN-TEST AUTOMATION/dataset & info/SDT UAR Test Cases/combined_keyword_driven.csv', index=False)\n",
        "combined_data_df.to_csv('/content/drive/MyDrive/WORKS/SOFTWARE-DRIVEN-TEST AUTOMATION/dataset & info/SDT UAR Test Cases/combined_data_driven.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h6DMBKXUgOd3"
      },
      "outputs": [],
      "source": [
        "# # Save the combined datasets\n",
        "combined_keyword_df.to_excel('/content/drive/MyDrive/WORKS/SOFTWARE-DRIVEN-TEST AUTOMATION/dataset & info/SDT UAR Test Cases/combined_keyword_driven.xlsx', index=False)\n",
        "combined_data_df.to_excel('/content/drive/MyDrive/WORKS/SOFTWARE-DRIVEN-TEST AUTOMATION/dataset & info/SDT UAR Test Cases/combined_data_driven.xlsx', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "beDMU6wDgX5U"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}